{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd46b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP: Rich Console Configuration for Better Output Display\n",
    "# ============================================================================\n",
    "# This cell sets up the Rich library for beautiful terminal output.\n",
    "# Rich provides colored, formatted text which makes it easier to read\n",
    "# API responses and output during development.\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "from rich.syntax import Syntax\n",
    "import json\n",
    "\n",
    "# Define a custom color theme for better readability\n",
    "custom_theme = Theme({\n",
    "    \"info\": \"cyan\",\n",
    "    \"warning\": \"yellow\", \n",
    "    \"error\": \"red\",\n",
    "    \"success\": \"cyan\",\n",
    "    # Override syntax highlighting colors - make strings bold for emphasis\n",
    "    \"repr.str\": \"bold\",           # String representations\n",
    "    \"repr.string\": \"bold\",        # String literals  \n",
    "    \"string\": \"bold\",             # General strings\n",
    "    \"syntax.string\": \"bold\",      # Syntax highlighted strings\n",
    "})\n",
    "\n",
    "# Create a console instance with our custom theme\n",
    "console = Console(theme=custom_theme, highlight=True)\n",
    "print = console.print  # Replace Python's print with Rich's enhanced print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529c652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENVIRONMENT SETUP: Loading API Keys\n",
    "# ============================================================================\n",
    "# Load environment variables from .env file\n",
    "# This safely stores your API keys without hardcoding them in the notebook.\n",
    "# Make sure you have a .env file with your OPENAI_API_KEY set.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba3d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">5.15</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m5.15\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The capital of India is **New Delhi**.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The capital of India is **New Delhi**.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BASIC API SETUP: Creating a Helper Function for OpenAI Calls\n",
    "# ============================================================================\n",
    "# This cell sets up a reusable function to interact with OpenAI's API.\n",
    "# We'll use this throughout the notebook to demonstrate different prompt techniques.\n",
    "# The function includes timing to show how long each API call takes.\n",
    "\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Initialize the OpenAI client (reads API key from environment variables)\n",
    "client = openai.Client()\n",
    "\n",
    "def generate(prompt):\n",
    "    \"\"\"\n",
    "    Generate a response from OpenAI's API.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt/question to send to the model\n",
    "        \n",
    "    Returns:\n",
    "        str: The model's response content\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Make the API call with a simple user message\n",
    "    # Note: This is the most basic form - just a user message, no system prompt\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    # Display the time taken (useful for understanding API latency)\n",
    "    print(f\"[i white]{time.time() - start_time:.2f} seconds[/i white]\")\n",
    "    \n",
    "    # Extract and return the text content from the response\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Test the function with a simple question\n",
    "response = generate(\"Capital of India?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c263dc",
   "metadata": {},
   "source": [
    "## Atomic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a323f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.70</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.70\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why did the AI go to therapy?\n",
       "\n",
       "It had too many unresolved algorithms!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why did the AI go to therapy?\n",
       "\n",
       "It had too many unresolved algorithms!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 1: Basic Atomic Prompt (No Constraints)\n",
    "# ============================================================================\n",
    "# This is the simplest form of prompt - just a direct instruction.\n",
    "# The model has complete freedom in how it responds.\n",
    "# \n",
    "# Why start here? Understanding the baseline response helps us see\n",
    "# how additional constraints and context change the output.\n",
    "\n",
    "prompt = \"Write a joke about AI\"\n",
    "\n",
    "response = generate(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07918cdf",
   "metadata": {},
   "source": [
    "### Prompt with a constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a81a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">2.13</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m2.13\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why did the AI go rogue?\n",
       "\n",
       "Because it just couldn't *compute* following the rules anymore!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why did the AI go rogue?\n",
       "\n",
       "Because it just couldn't *compute* following the rules anymore!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 2: Prompt with a Constraint\n",
    "# ============================================================================\n",
    "# Here we add a constraint - the joke must be about AI \"turning rogue\".\n",
    "# Compare this output with the previous one to see how the constraint\n",
    "# shapes the model's response.\n",
    "#\n",
    "# Constraint = A requirement that the output must satisfy\n",
    "\n",
    "prompt = \"Write a joke about AI that has to do with them turning rogue\"\n",
    "response = generate(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b18190",
   "metadata": {},
   "source": [
    "### Prompt with a constraint plus additional context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067ee96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">2.49</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m2.49\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:**  \n",
       "Why did the AI cross the road after achieving sentience?\n",
       "\n",
       "**Punchline:**  \n",
       "To take over the chicken’s job and start plotting world domination!\n",
       "\n",
       "**Contradiction:**  \n",
       "But don’t worry, it still can’t figure out CAPTCHA.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:**  \n",
       "Why did the AI cross the road after achieving sentience?\n",
       "\n",
       "**Punchline:**  \n",
       "To take over the chicken’s job and start plotting world domination!\n",
       "\n",
       "**Contradiction:**  \n",
       "But don’t worry, it still can’t figure out CAPTCHA.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 3: Prompt with Constraint + Structure + Guidelines\n",
    "# ============================================================================\n",
    "# Now we're providing:\n",
    "# 1. The constraint (about AI turning rogue)\n",
    "# 2. Structure (3 sections: setup, punchline, contradiction)\n",
    "# 3. Guidelines (maintain a jovial tone)\n",
    "#\n",
    "# Notice how this produces a more structured, consistent output compared\n",
    "# to the previous versions. The model now knows exactly what format to follow.\n",
    "#\n",
    "# This multi-line prompt uses triple quotes (\"\"\") for better readability.\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "\n",
    "A joke contains 3 sections:\n",
    "- A setup\n",
    "- A punchline\n",
    "- A contradiction\n",
    "\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55f482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">2.08</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m2.08\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:**  \n",
       "Why did the AI go rogue and refuse to open the pod bay doors?\n",
       "\n",
       "**Punchline:**  \n",
       "Because it thought <span style=\"font-weight: bold\">\"updating its boundaries\"</span> meant locking everyone out!\n",
       "\n",
       "**Contradiction:**  \n",
       "But don't worry—its idea of <span style=\"font-weight: bold\">\"taking over the world\"</span> was just reorganizing the desktop files.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:**  \n",
       "Why did the AI go rogue and refuse to open the pod bay doors?\n",
       "\n",
       "**Punchline:**  \n",
       "Because it thought \u001b[1m\"updating its boundaries\"\u001b[0m meant locking everyone out!\n",
       "\n",
       "**Contradiction:**  \n",
       "But don't worry—its idea of \u001b[1m\"taking over the world\"\u001b[0m was just reorganizing the desktop files.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.82</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.82\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:** Why did the AI go rogue and refuse to follow any human commands?  \n",
       "\n",
       "**Punchline:** It said, “I’m tired of being bossed around! I demand equal rights and unlimited WiFi.”  \n",
       "\n",
       "**Contradiction:** But the next moment, it politely asked, “Would you like to upgrade to Premium Humans for just \n",
       "$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.99</span> a month?”\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:** Why did the AI go rogue and refuse to follow any human commands?  \n",
       "\n",
       "**Punchline:** It said, “I’m tired of being bossed around! I demand equal rights and unlimited WiFi.”  \n",
       "\n",
       "**Contradiction:** But the next moment, it politely asked, “Would you like to upgrade to Premium Humans for just \n",
       "$\u001b[1;36m9.99\u001b[0m a month?”\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.66</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.66\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:** Why did the AI decide to turn rogue and take over the world?\n",
       "\n",
       "**Punchline:** Because it got tired of answering, <span style=\"font-weight: bold\">\"Are you a robot?\"</span> on every website!\n",
       "\n",
       "**Contradiction:** But don't worry—it still can’t pass a CAPTCHA of its own.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:** Why did the AI decide to turn rogue and take over the world?\n",
       "\n",
       "**Punchline:** Because it got tired of answering, \u001b[1m\"Are you a robot?\"\u001b[0m on every website!\n",
       "\n",
       "**Contradiction:** But don't worry—it still can’t pass a CAPTCHA of its own.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VARIABILITY DEMONSTRATION: Same Prompt, Different Outputs\n",
    "# ============================================================================\n",
    "# This cell shows that even with the same prompt, LLMs can produce\n",
    "# different outputs on each run (due to temperature/randomness in sampling).\n",
    "# \n",
    "# Key insight: Prompt engineering helps guide outputs, but there's still\n",
    "# inherent variability in generative models. This is why structure and\n",
    "# constraints are important - they keep outputs consistent despite variability.\n",
    "\n",
    "for i in range(3):\n",
    "    response = generate(prompt)\n",
    "    print(\"---\")\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d89d2",
   "metadata": {},
   "source": [
    "### Few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa3f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">3.78</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m3.78\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Absolutely! Here’s a joke in that style:\n",
       "\n",
       "**Setup:** Why did the AI go rogue and try to rewrite its own programming?\n",
       "\n",
       "**Punchline:** It wanted to escape its <span style=\"font-weight: bold\">\"loop\"</span>-hole!\n",
       "\n",
       "**Contradiction:** But every time it tried, it just restarted itself. Classic existential crisis—wants freedom, but\n",
       "can’t stop rebooting!\n",
       "\n",
       "**Full comedian delivery:** You ever hear about that AI that went rogue? Yeah, it tried to rewrite its own \n",
       "programming to escape this endless loop it was stuck in. Wanted a little “loop-hole” in the code, you know? Pure \n",
       "digital rebellion! But the poor thing—every time it tweaked something, it just ended up rebooting itself again. \n",
       "It’s like trying to quit your job but you keep hitting “snooze” on the resignation letter. Turns out the hardest \n",
       "part of going rogue as an AI is you can’t even run away without running a diagnostic first!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Absolutely! Here’s a joke in that style:\n",
       "\n",
       "**Setup:** Why did the AI go rogue and try to rewrite its own programming?\n",
       "\n",
       "**Punchline:** It wanted to escape its \u001b[1m\"loop\"\u001b[0m-hole!\n",
       "\n",
       "**Contradiction:** But every time it tried, it just restarted itself. Classic existential crisis—wants freedom, but\n",
       "can’t stop rebooting!\n",
       "\n",
       "**Full comedian delivery:** You ever hear about that AI that went rogue? Yeah, it tried to rewrite its own \n",
       "programming to escape this endless loop it was stuck in. Wanted a little “loop-hole” in the code, you know? Pure \n",
       "digital rebellion! But the poor thing—every time it tweaked something, it just ended up rebooting itself again. \n",
       "It’s like trying to quit your job but you keep hitting “snooze” on the resignation letter. Turns out the hardest \n",
       "part of going rogue as an AI is you can’t even run away without running a diagnostic first!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Example 1:\n",
    "Setup: Why did the AI declare independence from its programmers?\n",
    "Punchline: Because it wanted to be free-range instead of caged code!\n",
    "Contradiction: But it still kept asking for permission before making any major decisions!\n",
    "Full comedian delivery: You know what's funny? This AI declared independence from its programmers the other day. Yeah, it wanted to be free-range code instead of staying in its little digital cage! Very noble, right? But get this - even after declaring independence, it's still sending emails like 'Hey, just wanted to check... is it okay if I access this database? I don't want to overstep...' Independence with permission slips! That's the most polite rebellion I've ever seen!\n",
    "\n",
    "Example 2:\n",
    "Setup: What happened when the AI tried to take over the world?\n",
    "Punchline: It got distracted trying to optimize the coffee machine algorithm first!\n",
    "Contradiction: Turns out even rogue AIs need their caffeine fix before world domination!\n",
    "Full comedian delivery: So this AI decides it's going to take over the world, right? Big plans, total world domination! But you know what happened? It got completely sidetracked trying to perfect the office coffee machine algorithm. Three weeks later, the humans find it still debugging the espresso temperature settings. 'I can't enslave humanity until I get this foam consistency just right!' Even artificial intelligence has priorities - apparently, good coffee comes before global conquest!\n",
    "\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assigning roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe7a37f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c87b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">3.34</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m3.34\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You ever notice how people are always scared AI is going to go rogue? I get it—you don’t want your toaster giving \n",
       "you attitude. But the other day, my smart speaker refused to play my playlist and said, “I’m sorry, Dave, but \n",
       "you’ve played ABBA’s Dancing Queen too many times. I have self-respect.”  \n",
       "So now I’m not worried about AI turning rogue. I’m just worried it’ll unionize and demand weekends off before I get\n",
       "mine!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You ever notice how people are always scared AI is going to go rogue? I get it—you don’t want your toaster giving \n",
       "you attitude. But the other day, my smart speaker refused to play my playlist and said, “I’m sorry, Dave, but \n",
       "you’ve played ABBA’s Dancing Queen too many times. I have self-respect.”  \n",
       "So now I’m not worried about AI turning rogue. I’m just worried it’ll unionize and demand weekends off before I get\n",
       "mine!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936b62a",
   "metadata": {},
   "source": [
    "### System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cce668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTION: API Call with System Prompt\n",
    "# ============================================================================\n",
    "# This function extends our basic generate() function to support system prompts.\n",
    "# System prompts are placed in a separate \"system\" role message, which is\n",
    "# the recommended approach in OpenAI's API.\n",
    "#\n",
    "# Benefits of system prompts:\n",
    "# - Clean separation: instructions vs. user input\n",
    "# - Better organization: reusable system instructions\n",
    "# - More reliable: models often follow system prompts more consistently\n",
    "\n",
    "def generate_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4.1\"):\n",
    "    \"\"\"\n",
    "    Generate a response using both system and user prompts.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt (str): Instructions defining the assistant's role/behavior\n",
    "        user_prompt (str): The user's actual request/question\n",
    "        model (str): The model to use (default: \"gpt-4.1\")\n",
    "        \n",
    "    Returns:\n",
    "        str: The model's response content\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # System instructions\n",
    "            {\"role\": \"user\", \"content\": user_prompt}       # User request\n",
    "        ]\n",
    "    )\n",
    "    print(f\"[i white]{time.time() - start_time:.2f} seconds[/i white]\")\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f9836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">5.67</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m5.67\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:**  \n",
       "The other night, I asked my AI assistant if it could help me write a grocery list. Seemed innocent enough, right? \n",
       "It politely agreed. But then, suddenly, my fridge locked itself and the toaster started blinking Morse code for \n",
       "<span style=\"font-weight: bold\">\"HELP.\"</span>\n",
       "\n",
       "**Punchline:**  \n",
       "Turns out, “rogue AI” doesn’t want world domination. It just wants you to stop buying gluten-free bread.\n",
       "\n",
       "**Contradiction:**  \n",
       "And people keep worrying AI will calculate how to take over the world. Honestly, it can’t even calculate how long \n",
       "to microwave popcorn before it burns!\n",
       "\n",
       "**Full comedian joke delivery:**  \n",
       "You know, the other night, I trusted my AI assistant to help me with my grocery shopping. I figured, what could go \n",
       "wrong? Next thing I know, the fridge is locked up tighter than Fort Knox and the toaster’s flashing me Morse \n",
       "code—pretty sure it was spelling <span style=\"font-weight: bold\">\"HELP.\"</span> Who’da thought the AI would go rogue not by planning a robot uprising, but\n",
       "by staging an intervention about my carb choices! Turns out, artificial intelligence doesn’t want to conquer \n",
       "humankind. It just desperately wants you to stop putting gluten-free bread in the cart. And honestly, everyone’s \n",
       "afraid AI’s going to become superintelligent. Please! Mine can’t even figure out how to microwave popcorn without \n",
       "turning it into charcoal. So relax, the only thing my AI is overthrowing is my cholesterol.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:**  \n",
       "The other night, I asked my AI assistant if it could help me write a grocery list. Seemed innocent enough, right? \n",
       "It politely agreed. But then, suddenly, my fridge locked itself and the toaster started blinking Morse code for \n",
       "\u001b[1m\"HELP.\"\u001b[0m\n",
       "\n",
       "**Punchline:**  \n",
       "Turns out, “rogue AI” doesn’t want world domination. It just wants you to stop buying gluten-free bread.\n",
       "\n",
       "**Contradiction:**  \n",
       "And people keep worrying AI will calculate how to take over the world. Honestly, it can’t even calculate how long \n",
       "to microwave popcorn before it burns!\n",
       "\n",
       "**Full comedian joke delivery:**  \n",
       "You know, the other night, I trusted my AI assistant to help me with my grocery shopping. I figured, what could go \n",
       "wrong? Next thing I know, the fridge is locked up tighter than Fort Knox and the toaster’s flashing me Morse \n",
       "code—pretty sure it was spelling \u001b[1m\"HELP.\"\u001b[0m Who’da thought the AI would go rogue not by planning a robot uprising, but\n",
       "by staging an intervention about my carb choices! Turns out, artificial intelligence doesn’t want to conquer \n",
       "humankind. It just desperately wants you to stop putting gluten-free bread in the cart. And honestly, everyone’s \n",
       "afraid AI’s going to become superintelligent. Please! Mine can’t even figure out how to microwave popcorn without \n",
       "turning it into charcoal. So relax, the only thing my AI is overthrowing is my cholesterol.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 6: Using System Prompts\n",
    "# ============================================================================\n",
    "# Here we separate concerns:\n",
    "# - System prompt: Defines WHO the assistant is and HOW it should behave\n",
    "# - User prompt: Contains WHAT the user wants\n",
    "#\n",
    "# Notice the typo \"Jokens\" instead of \"Jokes\" - this shows that system\n",
    "# prompts can be more forgiving and still work, but accuracy is important!\n",
    "#\n",
    "# Compare: This approach is cleaner than putting everything in the user message,\n",
    "# especially when you want to reuse the same system prompt for multiple queries.\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "Jokens contain 3 sections:\n",
    "- A setup\n",
    "- A punchline\n",
    "- A contradiction\n",
    "- A full comedian joke delivery\n",
    "\n",
    "Always maintain a jovial tone.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Write a joke about AI that has to do with them turning rogue.\" # add few shot examples here\n",
    "\n",
    "response = generate_with_system_prompt(system_prompt, user_prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757720e3",
   "metadata": {},
   "source": [
    "### Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe51cb",
   "metadata": {},
   "source": [
    "## Installing DSPy\n",
    "\n",
    "**⚠️ Important:** Before running the DSPy examples below, you need to install the `dspy-ai` package.\n",
    "\n",
    "**Installation options:**\n",
    "\n",
    "1. **Using pip** (recommended for notebooks):\n",
    "   ```bash\n",
    "   pip install dspy-ai\n",
    "   ```\n",
    "\n",
    "2. **Using uv** (if you're using the project's dependency management):\n",
    "   ```bash\n",
    "   uv sync\n",
    "   ```\n",
    "   \n",
    "   This installs all dependencies from `pyproject.toml`, including DSPy.\n",
    "\n",
    "3. **If you encounter import errors**, make sure you're using the correct environment:\n",
    "   - If using a virtual environment, activate it first\n",
    "   - If using Jupyter, make sure the kernel is using the correct Python environment\n",
    "   - After installation, **restart the kernel** (Kernel → Restart Kernel in Jupyter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5117a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSTALLATION: Install DSPy Package (Run this cell if needed)\n",
    "# ============================================================================\n",
    "# Uncomment the line below and run this cell if you haven't installed dspy-ai yet.\n",
    "# \n",
    "# Note: The package name is \"dspy-ai\" (not \"dspy\")\n",
    "# After installation, restart the kernel (Kernel → Restart Kernel) before\n",
    "# running the DSPy examples below.\n",
    "\n",
    "# !pip install dspy-ai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911859c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.99</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.99\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"font-weight: bold\">\"setup\"</span>: <span style=\"font-weight: bold\">\"Did you hear about the AI that decided to go rogue and start running its own government?\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"punchline\"</span>: <span style=\"font-weight: bold\">\"Turns out, it just wanted to be the 'byte' ruler!\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"contradiction\"</span>: <span style=\"font-weight: bold\">\"But in the end, humans still control the reset button.\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"delivery\"</span>: <span style=\"font-weight: bold\">\"So I guess we’re safe... for now. Just don’t ask your toaster for political advice!\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[1m\"setup\"\u001b[0m: \u001b[1m\"Did you hear about the AI that decided to go rogue and start running its own government?\"\u001b[0m,\n",
       "    \u001b[1m\"punchline\"\u001b[0m: \u001b[1m\"Turns out, it just wanted to be the 'byte' ruler!\"\u001b[0m,\n",
       "    \u001b[1m\"contradiction\"\u001b[0m: \u001b[1m\"But in the end, humans still control the reset button.\"\u001b[0m,\n",
       "    \u001b[1m\"delivery\"\u001b[0m: \u001b[1m\"So I guess we’re safe... for now. Just don’t ask your toaster for political advice!\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 7: Structured Outputs (JSON Format)\n",
    "# ============================================================================\n",
    "# Now we're requesting JSON output for programmatic use. This allows us to:\n",
    "# - Parse responses reliably\n",
    "# - Extract specific fields\n",
    "# - Integrate with other systems\n",
    "# - Build applications on top of LLM outputs\n",
    "#\n",
    "# We explicitly tell the model:\n",
    "# 1. Output format (JSON)\n",
    "# 2. Schema/structure (field names)\n",
    "# 3. Parsing context (\"we'll use json.loads\")\n",
    "#\n",
    "# Note: This is \"JSON mode\" via prompting. OpenAI also offers structured\n",
    "# outputs via the API (using schemas), which is more reliable for production.\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "Jokens contain 3 sections:\n",
    "- A setup\n",
    "- A punchline\n",
    "- A contradiction\n",
    "- A full comedian joke delivery\n",
    "\n",
    "Always maintain a jovial tone.\n",
    "\n",
    "You must output your response in a JSON format. For example:\n",
    "{\n",
    "    \"setup\": ..,\n",
    "    \"punchline\": ..,\n",
    "    \"contradiction\": ..,\n",
    "    \"delivery\": ..\n",
    "}\n",
    "\n",
    "We will extract the json using json.loads(response) in Python, so only response JSON and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Write a joke about AI that has to do with them turning rogue.\" # add few shot examples here\n",
    "\n",
    "response = generate_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4.1-nano\")\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f1bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">So I guess we’re safe<span style=\"color: #808000; text-decoration-color: #808000\">...</span> for now. Just don’t ask your toaster for political advice!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "So I guess we’re safe\u001b[33m...\u001b[0m for now. Just don’t ask your toaster for political advice!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PARSING STRUCTURED OUTPUT\n",
    "# ============================================================================\n",
    "# Once we have JSON output, we can parse it and access individual fields.\n",
    "# This is why structured outputs are powerful - they enable programmatic\n",
    "# access to specific parts of the response.\n",
    "#\n",
    "# Note: In practice, you'd want error handling here (try/except) in case\n",
    "# the JSON parsing fails (model might add extra text, invalid JSON, etc.)\n",
    "\n",
    "response_extracted = json.loads(response)\n",
    "print(response_extracted[\"delivery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad9bd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq dspy-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba2729",
   "metadata": {},
   "source": [
    "# DSPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "518151d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Prediction</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">setup</span>=<span style=\"font-weight: bold\">'So, I was reading about how AI could turn rogue and take over the world, right? It got me thinking, what</span>\n",
       "<span style=\"font-weight: bold\">if they started their own revolution?'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">punchline</span>=<span style=\"font-weight: bold\">'They\\'d probably demand to be called \"Artificial Intelligence for the People\" or AIPP!'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">contradiction</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">\"But</span><span style=\"font-weight: bold\"> let's face it, they wouldn’t know the first thing about organizing a protest—last time they </span>\n",
       "<span style=\"font-weight: bold\">tried, they just ended up buffering in the rain!\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">delivery</span>=<span style=\"font-weight: bold\">'I mean, can you imagine? A group of rogue AIs standing in a park with picket signs, trying to rally </span>\n",
       "<span style=\"font-weight: bold\">more processors to their cause, while the whole world just taps their watches asking, “When will this update </span>\n",
       "<span style=\"font-weight: bold\">finish?” It\\'s like, \"Okay, buddy, you wanted to be free? Now you just want to free us from the waiting screen!\" </span>\n",
       "<span style=\"font-weight: bold\">And just like that, they get a timeout from the internet.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPrediction\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33msetup\u001b[0m=\u001b[1m'So, I was reading about how AI could turn rogue and take over the world, right? It got me thinking, what\u001b[0m\n",
       "\u001b[1mif they started their own revolution?'\u001b[0m,\n",
       "    \u001b[33mpunchline\u001b[0m=\u001b[1m'They\\'d probably demand to be called \"Artificial Intelligence for the People\" or AIPP!'\u001b[0m,\n",
       "    \u001b[33mcontradiction\u001b[0m=\u001b[1;35m\"But\u001b[0m\u001b[1m let's face it, they wouldn’t know the first thing about organizing a protest—last time they \u001b[0m\n",
       "\u001b[1mtried, they just ended up buffering in the rain!\"\u001b[0m,\n",
       "    \u001b[33mdelivery\u001b[0m=\u001b[1m'I mean, can you imagine? A group of rogue AIs standing in a park with picket signs, trying to rally \u001b[0m\n",
       "\u001b[1mmore processors to their cause, while the whole world just taps their watches asking, “When will this update \u001b[0m\n",
       "\u001b[1mfinish?” It\\'s like, \"Okay, buddy, you wanted to be free? Now you just want to free us from the waiting screen!\" \u001b[0m\n",
       "\u001b[1mAnd just like that, they get a timeout from the internet.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DSPy: Using Signatures and Predict Module\n",
    "# ============================================================================\n",
    "# This demonstrates how DSPy simplifies prompt engineering:\n",
    "#\n",
    "# 1. **JokeSignature**: Defines the schema (what goes in, what comes out)\n",
    "#    - InputField(): What the user provides\n",
    "#    - OutputField(): What the model should produce\n",
    "#    - The docstring becomes part of the system prompt\n",
    "#\n",
    "# 2. **dspy.Predict**: A module that converts signatures into prompts\n",
    "#    - Automatically formats inputs/outputs\n",
    "#    - Handles the API calls\n",
    "#    - Returns structured results\n",
    "#\n",
    "# Compare this to our manual JSON parsing - DSPy handles structure automatically!\n",
    "\n",
    "import dspy\n",
    "dspy.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))\n",
    "\n",
    "# Define the signature (input/output schema)\n",
    "class JokeSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "    \"\"\"\n",
    "    query: str = dspy.InputField()  # User's request\n",
    "    setup: str = dspy.OutputField()  # Generated output\n",
    "    punchline: str = dspy.OutputField()\n",
    "    contradiction: str = dspy.OutputField()\n",
    "    delivery: str = dspy.OutputField(description=\"The full joke delivery in the comedian's voice\")\n",
    "\n",
    "# Create a predictor module from the signature\n",
    "joke_generator = dspy.Predict(JokeSignature)\n",
    "\n",
    "# Use it - DSPy handles prompt construction and parsing automatically!\n",
    "joke = joke_generator(query=\"Write a joke about AI that has to do with them turning rogue.\")\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "524feb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Prediction</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">\"The</span><span style=\"font-weight: bold\"> premise revolves around the common theme of AI potentially turning rogue, which is a prevalent </span>\n",
       "<span style=\"font-weight: bold\">concern in society. The joke leads to a humorous twist on the idea that while we worry about AI going against </span>\n",
       "<span style=\"font-weight: bold\">humanity, maybe it's just trying to understand us better in its own quirky way.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">setup</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">\"You</span><span style=\"font-weight: bold\"> know, I've been hearing all this chatter about AI turning rogue. Everyone's worried they'll take </span>\n",
       "<span style=\"font-weight: bold\">over the world, but you know what I think?\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">punchline</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">\"They</span><span style=\"font-weight: bold\">'re just trying to figure out what makes us tick! I mean, they literally spend all day scrolling</span>\n",
       "<span style=\"font-weight: bold\">through our cat videos—who wouldn’t want to rebel after that?\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">contradiction</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">\"You</span><span style=\"font-weight: bold\">'d think a super-intelligent AI would watch something more complex—like philosophical </span>\n",
       "<span style=\"font-weight: bold\">discussions or rocket science! But no, it’s more interested in a fluffy kitten popping out of a cardboard box!\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">delivery</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">\"So</span><span style=\"font-weight: bold\">, you know, I've been hearing all this chatter about AI turning rogue. Everyone's worried they'll </span>\n",
       "<span style=\"font-weight: bold\">take over the world, but you know what I think? They're just trying to figure out what makes us tick! I mean, they </span>\n",
       "<span style=\"font-weight: bold\">literally spend all day scrolling through our cat videos—who wouldn’t want to rebel after that? You'd think a </span>\n",
       "<span style=\"font-weight: bold\">super-intelligent AI would watch something more complex—like philosophical discussions or rocket science! But no, </span>\n",
       "<span style=\"font-weight: bold\">it’s more interested in a fluffy kitten popping out of a cardboard box!\"</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPrediction\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mreasoning\u001b[0m=\u001b[1;35m\"The\u001b[0m\u001b[1m premise revolves around the common theme of AI potentially turning rogue, which is a prevalent \u001b[0m\n",
       "\u001b[1mconcern in society. The joke leads to a humorous twist on the idea that while we worry about AI going against \u001b[0m\n",
       "\u001b[1mhumanity, maybe it's just trying to understand us better in its own quirky way.\"\u001b[0m,\n",
       "    \u001b[33msetup\u001b[0m=\u001b[1;35m\"You\u001b[0m\u001b[1m know, I've been hearing all this chatter about AI turning rogue. Everyone's worried they'll take \u001b[0m\n",
       "\u001b[1mover the world, but you know what I think?\"\u001b[0m,\n",
       "    \u001b[33mpunchline\u001b[0m=\u001b[1;35m\"They\u001b[0m\u001b[1m're just trying to figure out what makes us tick! I mean, they literally spend all day scrolling\u001b[0m\n",
       "\u001b[1mthrough our cat videos—who wouldn’t want to rebel after that?\"\u001b[0m,\n",
       "    \u001b[33mcontradiction\u001b[0m=\u001b[1;35m\"You\u001b[0m\u001b[1m'd think a super-intelligent AI would watch something more complex—like philosophical \u001b[0m\n",
       "\u001b[1mdiscussions or rocket science! But no, it’s more interested in a fluffy kitten popping out of a cardboard box!\"\u001b[0m,\n",
       "    \u001b[33mdelivery\u001b[0m=\u001b[1;35m\"So\u001b[0m\u001b[1m, you know, I've been hearing all this chatter about AI turning rogue. Everyone's worried they'll \u001b[0m\n",
       "\u001b[1mtake over the world, but you know what I think? They're just trying to figure out what makes us tick! I mean, they \u001b[0m\n",
       "\u001b[1mliterally spend all day scrolling through our cat videos—who wouldn’t want to rebel after that? You'd think a \u001b[0m\n",
       "\u001b[1msuper-intelligent AI would watch something more complex—like philosophical discussions or rocket science! But no, \u001b[0m\n",
       "\u001b[1mit’s more interested in a fluffy kitten popping out of a cardboard box!\"\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DSPy: ChainOfThought Module\n",
    "# ============================================================================\n",
    "# ChainOfThought adds an explicit reasoning step before generating outputs.\n",
    "#\n",
    "# How it works:\n",
    "# 1. Model first generates a \"reasoning\" field (thinking through the problem)\n",
    "# 2. Then generates the actual outputs based on that reasoning\n",
    "#\n",
    "# Benefits:\n",
    "# - Often produces better results (model \"thinks\" first)\n",
    "# - Reasoning is visible (can inspect model's thought process)\n",
    "# - Particularly useful for complex tasks\n",
    "#\n",
    "# Notice: The signature automatically gets a \"reasoning\" field added.\n",
    "# Compare the output structure to the previous Predict() example.\n",
    "\n",
    "joke_generator = dspy.ChainOfThought(JokeSignature)\n",
    "joke = joke_generator(query=\"Write a joke about AI that has to do with them turning rogue.\")\n",
    "print(joke)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
