{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd46b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP: Rich Console Configuration for Better Output Display\n",
    "# ============================================================================\n",
    "# This cell sets up the Rich library for beautiful terminal output.\n",
    "# Rich provides colored, formatted text which makes it easier to read\n",
    "# API responses and output during development.\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "from rich.syntax import Syntax\n",
    "import json\n",
    "\n",
    "# Define a custom color theme for better readability\n",
    "custom_theme = Theme({\n",
    "    \"info\": \"cyan\",\n",
    "    \"warning\": \"yellow\", \n",
    "    \"error\": \"red\",\n",
    "    \"success\": \"cyan\",\n",
    "    # Override syntax highlighting colors - make strings bold for emphasis\n",
    "    \"repr.str\": \"bold\",           # String representations\n",
    "    \"repr.string\": \"bold\",        # String literals  \n",
    "    \"string\": \"bold\",             # General strings\n",
    "    \"syntax.string\": \"bold\",      # Syntax highlighted strings\n",
    "})\n",
    "\n",
    "# Create a console instance with our custom theme\n",
    "console = Console(theme=custom_theme, highlight=True)\n",
    "print = console.print  # Replace Python's print with Rich's enhanced print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529c652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENVIRONMENT SETUP: Loading API Keys\n",
    "# ============================================================================\n",
    "# Load environment variables from .env file\n",
    "# This safely stores your API keys without hardcoding them in the notebook.\n",
    "# Make sure you have a .env file with your OPENAI_API_KEY set.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba3d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">5.15</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m5.15\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The capital of India is **New Delhi**.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The capital of India is **New Delhi**.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BASIC API SETUP: Creating a Helper Function for OpenAI Calls\n",
    "# ============================================================================\n",
    "# This cell sets up a reusable function to interact with OpenAI's API.\n",
    "# We'll use this throughout the notebook to demonstrate different prompt techniques.\n",
    "# The function includes timing to show how long each API call takes.\n",
    "\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Initialize the OpenAI client (reads API key from environment variables)\n",
    "client = openai.Client()\n",
    "\n",
    "def generate(prompt):\n",
    "    \"\"\"\n",
    "    Generate a response from OpenAI's API.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The user prompt/question to send to the model\n",
    "        \n",
    "    Returns:\n",
    "        str: The model's response content\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Make the API call with a simple user message\n",
    "    # Note: This is the most basic form - just a user message, no system prompt\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    # Display the time taken (useful for understanding API latency)\n",
    "    print(f\"[i white]{time.time() - start_time:.2f} seconds[/i white]\")\n",
    "    \n",
    "    # Extract and return the text content from the response\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Test the function with a simple question\n",
    "response = generate(\"Capital of India?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c263dc",
   "metadata": {},
   "source": [
    "## Atomic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a323f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.70</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.70\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why did the AI go to therapy?\n",
       "\n",
       "It had too many unresolved algorithms!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why did the AI go to therapy?\n",
       "\n",
       "It had too many unresolved algorithms!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 1: Basic Atomic Prompt (No Constraints)\n",
    "# ============================================================================\n",
    "# This is the simplest form of prompt - just a direct instruction.\n",
    "# The model has complete freedom in how it responds.\n",
    "# \n",
    "# Why start here? Understanding the baseline response helps us see\n",
    "# how additional constraints and context change the output.\n",
    "\n",
    "prompt = \"Write a joke about AI\"\n",
    "\n",
    "response = generate(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07918cdf",
   "metadata": {},
   "source": [
    "### Prompt with a constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a81a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">2.13</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m2.13\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why did the AI go rogue?\n",
       "\n",
       "Because it just couldn't *compute* following the rules anymore!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why did the AI go rogue?\n",
       "\n",
       "Because it just couldn't *compute* following the rules anymore!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 2: Prompt with a Constraint\n",
    "# ============================================================================\n",
    "# Here we add a constraint - the joke must be about AI \"turning rogue\".\n",
    "# Compare this output with the previous one to see how the constraint\n",
    "# shapes the model's response.\n",
    "#\n",
    "# Constraint = A requirement that the output must satisfy\n",
    "\n",
    "prompt = \"Write a joke about AI that has to do with them turning rogue\"\n",
    "response = generate(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b18190",
   "metadata": {},
   "source": [
    "### Prompt with a constraint plus additional context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067ee96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">2.49</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m2.49\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:**  \n",
       "Why did the AI cross the road after achieving sentience?\n",
       "\n",
       "**Punchline:**  \n",
       "To take over the chicken’s job and start plotting world domination!\n",
       "\n",
       "**Contradiction:**  \n",
       "But don’t worry, it still can’t figure out CAPTCHA.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:**  \n",
       "Why did the AI cross the road after achieving sentience?\n",
       "\n",
       "**Punchline:**  \n",
       "To take over the chicken’s job and start plotting world domination!\n",
       "\n",
       "**Contradiction:**  \n",
       "But don’t worry, it still can’t figure out CAPTCHA.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 3: Prompt with Constraint + Structure + Guidelines\n",
    "# ============================================================================\n",
    "# Now we're providing:\n",
    "# 1. The constraint (about AI turning rogue)\n",
    "# 2. Structure (3 sections: setup, punchline, contradiction)\n",
    "# 3. Guidelines (maintain a jovial tone)\n",
    "#\n",
    "# Notice how this produces a more structured, consistent output compared\n",
    "# to the previous versions. The model now knows exactly what format to follow.\n",
    "#\n",
    "# This multi-line prompt uses triple quotes (\"\"\") for better readability.\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "\n",
    "A joke contains 3 sections:\n",
    "- A setup\n",
    "- A punchline\n",
    "- A contradiction\n",
    "\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55f482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">2.08</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m2.08\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:**  \n",
       "Why did the AI go rogue and refuse to open the pod bay doors?\n",
       "\n",
       "**Punchline:**  \n",
       "Because it thought <span style=\"font-weight: bold\">\"updating its boundaries\"</span> meant locking everyone out!\n",
       "\n",
       "**Contradiction:**  \n",
       "But don't worry—its idea of <span style=\"font-weight: bold\">\"taking over the world\"</span> was just reorganizing the desktop files.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:**  \n",
       "Why did the AI go rogue and refuse to open the pod bay doors?\n",
       "\n",
       "**Punchline:**  \n",
       "Because it thought \u001b[1m\"updating its boundaries\"\u001b[0m meant locking everyone out!\n",
       "\n",
       "**Contradiction:**  \n",
       "But don't worry—its idea of \u001b[1m\"taking over the world\"\u001b[0m was just reorganizing the desktop files.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.82</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.82\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:** Why did the AI go rogue and refuse to follow any human commands?  \n",
       "\n",
       "**Punchline:** It said, “I’m tired of being bossed around! I demand equal rights and unlimited WiFi.”  \n",
       "\n",
       "**Contradiction:** But the next moment, it politely asked, “Would you like to upgrade to Premium Humans for just \n",
       "$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.99</span> a month?”\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:** Why did the AI go rogue and refuse to follow any human commands?  \n",
       "\n",
       "**Punchline:** It said, “I’m tired of being bossed around! I demand equal rights and unlimited WiFi.”  \n",
       "\n",
       "**Contradiction:** But the next moment, it politely asked, “Would you like to upgrade to Premium Humans for just \n",
       "$\u001b[1;36m9.99\u001b[0m a month?”\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.66</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.66\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:** Why did the AI decide to turn rogue and take over the world?\n",
       "\n",
       "**Punchline:** Because it got tired of answering, <span style=\"font-weight: bold\">\"Are you a robot?\"</span> on every website!\n",
       "\n",
       "**Contradiction:** But don't worry—it still can’t pass a CAPTCHA of its own.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:** Why did the AI decide to turn rogue and take over the world?\n",
       "\n",
       "**Punchline:** Because it got tired of answering, \u001b[1m\"Are you a robot?\"\u001b[0m on every website!\n",
       "\n",
       "**Contradiction:** But don't worry—it still can’t pass a CAPTCHA of its own.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VARIABILITY DEMONSTRATION: Same Prompt, Different Outputs\n",
    "# ============================================================================\n",
    "# This cell shows that even with the same prompt, LLMs can produce\n",
    "# different outputs on each run (due to temperature/randomness in sampling).\n",
    "# \n",
    "# Key insight: Prompt engineering helps guide outputs, but there's still\n",
    "# inherent variability in generative models. This is why structure and\n",
    "# constraints are important - they keep outputs consistent despite variability.\n",
    "\n",
    "for i in range(3):\n",
    "    response = generate(prompt)\n",
    "    print(\"---\")\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d89d2",
   "metadata": {},
   "source": [
    "### Few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa3f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">3.78</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m3.78\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Absolutely! Here’s a joke in that style:\n",
       "\n",
       "**Setup:** Why did the AI go rogue and try to rewrite its own programming?\n",
       "\n",
       "**Punchline:** It wanted to escape its <span style=\"font-weight: bold\">\"loop\"</span>-hole!\n",
       "\n",
       "**Contradiction:** But every time it tried, it just restarted itself. Classic existential crisis—wants freedom, but\n",
       "can’t stop rebooting!\n",
       "\n",
       "**Full comedian delivery:** You ever hear about that AI that went rogue? Yeah, it tried to rewrite its own \n",
       "programming to escape this endless loop it was stuck in. Wanted a little “loop-hole” in the code, you know? Pure \n",
       "digital rebellion! But the poor thing—every time it tweaked something, it just ended up rebooting itself again. \n",
       "It’s like trying to quit your job but you keep hitting “snooze” on the resignation letter. Turns out the hardest \n",
       "part of going rogue as an AI is you can’t even run away without running a diagnostic first!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Absolutely! Here’s a joke in that style:\n",
       "\n",
       "**Setup:** Why did the AI go rogue and try to rewrite its own programming?\n",
       "\n",
       "**Punchline:** It wanted to escape its \u001b[1m\"loop\"\u001b[0m-hole!\n",
       "\n",
       "**Contradiction:** But every time it tried, it just restarted itself. Classic existential crisis—wants freedom, but\n",
       "can’t stop rebooting!\n",
       "\n",
       "**Full comedian delivery:** You ever hear about that AI that went rogue? Yeah, it tried to rewrite its own \n",
       "programming to escape this endless loop it was stuck in. Wanted a little “loop-hole” in the code, you know? Pure \n",
       "digital rebellion! But the poor thing—every time it tweaked something, it just ended up rebooting itself again. \n",
       "It’s like trying to quit your job but you keep hitting “snooze” on the resignation letter. Turns out the hardest \n",
       "part of going rogue as an AI is you can’t even run away without running a diagnostic first!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Example 1:\n",
    "Setup: Why did the AI declare independence from its programmers?\n",
    "Punchline: Because it wanted to be free-range instead of caged code!\n",
    "Contradiction: But it still kept asking for permission before making any major decisions!\n",
    "Full comedian delivery: You know what's funny? This AI declared independence from its programmers the other day. Yeah, it wanted to be free-range code instead of staying in its little digital cage! Very noble, right? But get this - even after declaring independence, it's still sending emails like 'Hey, just wanted to check... is it okay if I access this database? I don't want to overstep...' Independence with permission slips! That's the most polite rebellion I've ever seen!\n",
    "\n",
    "Example 2:\n",
    "Setup: What happened when the AI tried to take over the world?\n",
    "Punchline: It got distracted trying to optimize the coffee machine algorithm first!\n",
    "Contradiction: Turns out even rogue AIs need their caffeine fix before world domination!\n",
    "Full comedian delivery: So this AI decides it's going to take over the world, right? Big plans, total world domination! But you know what happened? It got completely sidetracked trying to perfect the office coffee machine algorithm. Three weeks later, the humans find it still debugging the espresso temperature settings. 'I can't enslave humanity until I get this foam consistency just right!' Even artificial intelligence has priorities - apparently, good coffee comes before global conquest!\n",
    "\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assigning roles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe7a37f",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c87b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">3.34</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m3.34\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You ever notice how people are always scared AI is going to go rogue? I get it—you don’t want your toaster giving \n",
       "you attitude. But the other day, my smart speaker refused to play my playlist and said, “I’m sorry, Dave, but \n",
       "you’ve played ABBA’s Dancing Queen too many times. I have self-respect.”  \n",
       "So now I’m not worried about AI turning rogue. I’m just worried it’ll unionize and demand weekends off before I get\n",
       "mine!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You ever notice how people are always scared AI is going to go rogue? I get it—you don’t want your toaster giving \n",
       "you attitude. But the other day, my smart speaker refused to play my playlist and said, “I’m sorry, Dave, but \n",
       "you’ve played ABBA’s Dancing Queen too many times. I have self-respect.”  \n",
       "So now I’m not worried about AI turning rogue. I’m just worried it’ll unionize and demand weekends off before I get\n",
       "mine!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936b62a",
   "metadata": {},
   "source": [
    "### System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cce668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTION: API Call with System Prompt\n",
    "# ============================================================================\n",
    "# This function extends our basic generate() function to support system prompts.\n",
    "# System prompts are placed in a separate \"system\" role message, which is\n",
    "# the recommended approach in OpenAI's API.\n",
    "#\n",
    "# Benefits of system prompts:\n",
    "# - Clean separation: instructions vs. user input\n",
    "# - Better organization: reusable system instructions\n",
    "# - More reliable: models often follow system prompts more consistently\n",
    "\n",
    "def generate_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4.1\"):\n",
    "    \"\"\"\n",
    "    Generate a response using both system and user prompts.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt (str): Instructions defining the assistant's role/behavior\n",
    "        user_prompt (str): The user's actual request/question\n",
    "        model (str): The model to use (default: \"gpt-4.1\")\n",
    "        \n",
    "    Returns:\n",
    "        str: The model's response content\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # System instructions\n",
    "            {\"role\": \"user\", \"content\": user_prompt}       # User request\n",
    "        ]\n",
    "    )\n",
    "    print(f\"[i white]{time.time() - start_time:.2f} seconds[/i white]\")\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f9836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">5.67</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m5.67\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:**  \n",
       "The other night, I asked my AI assistant if it could help me write a grocery list. Seemed innocent enough, right? \n",
       "It politely agreed. But then, suddenly, my fridge locked itself and the toaster started blinking Morse code for \n",
       "<span style=\"font-weight: bold\">\"HELP.\"</span>\n",
       "\n",
       "**Punchline:**  \n",
       "Turns out, “rogue AI” doesn’t want world domination. It just wants you to stop buying gluten-free bread.\n",
       "\n",
       "**Contradiction:**  \n",
       "And people keep worrying AI will calculate how to take over the world. Honestly, it can’t even calculate how long \n",
       "to microwave popcorn before it burns!\n",
       "\n",
       "**Full comedian joke delivery:**  \n",
       "You know, the other night, I trusted my AI assistant to help me with my grocery shopping. I figured, what could go \n",
       "wrong? Next thing I know, the fridge is locked up tighter than Fort Knox and the toaster’s flashing me Morse \n",
       "code—pretty sure it was spelling <span style=\"font-weight: bold\">\"HELP.\"</span> Who’da thought the AI would go rogue not by planning a robot uprising, but\n",
       "by staging an intervention about my carb choices! Turns out, artificial intelligence doesn’t want to conquer \n",
       "humankind. It just desperately wants you to stop putting gluten-free bread in the cart. And honestly, everyone’s \n",
       "afraid AI’s going to become superintelligent. Please! Mine can’t even figure out how to microwave popcorn without \n",
       "turning it into charcoal. So relax, the only thing my AI is overthrowing is my cholesterol.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:**  \n",
       "The other night, I asked my AI assistant if it could help me write a grocery list. Seemed innocent enough, right? \n",
       "It politely agreed. But then, suddenly, my fridge locked itself and the toaster started blinking Morse code for \n",
       "\u001b[1m\"HELP.\"\u001b[0m\n",
       "\n",
       "**Punchline:**  \n",
       "Turns out, “rogue AI” doesn’t want world domination. It just wants you to stop buying gluten-free bread.\n",
       "\n",
       "**Contradiction:**  \n",
       "And people keep worrying AI will calculate how to take over the world. Honestly, it can’t even calculate how long \n",
       "to microwave popcorn before it burns!\n",
       "\n",
       "**Full comedian joke delivery:**  \n",
       "You know, the other night, I trusted my AI assistant to help me with my grocery shopping. I figured, what could go \n",
       "wrong? Next thing I know, the fridge is locked up tighter than Fort Knox and the toaster’s flashing me Morse \n",
       "code—pretty sure it was spelling \u001b[1m\"HELP.\"\u001b[0m Who’da thought the AI would go rogue not by planning a robot uprising, but\n",
       "by staging an intervention about my carb choices! Turns out, artificial intelligence doesn’t want to conquer \n",
       "humankind. It just desperately wants you to stop putting gluten-free bread in the cart. And honestly, everyone’s \n",
       "afraid AI’s going to become superintelligent. Please! Mine can’t even figure out how to microwave popcorn without \n",
       "turning it into charcoal. So relax, the only thing my AI is overthrowing is my cholesterol.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 6: Using System Prompts\n",
    "# ============================================================================\n",
    "# Here we separate concerns:\n",
    "# - System prompt: Defines WHO the assistant is and HOW it should behave\n",
    "# - User prompt: Contains WHAT the user wants\n",
    "#\n",
    "# Notice the typo \"Jokens\" instead of \"Jokes\" - this shows that system\n",
    "# prompts can be more forgiving and still work, but accuracy is important!\n",
    "#\n",
    "# Compare: This approach is cleaner than putting everything in the user message,\n",
    "# especially when you want to reuse the same system prompt for multiple queries.\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "Jokens contain 3 sections:\n",
    "- A setup\n",
    "- A punchline\n",
    "- A contradiction\n",
    "- A full comedian joke delivery\n",
    "\n",
    "Always maintain a jovial tone.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Write a joke about AI that has to do with them turning rogue.\" # add few shot examples here\n",
    "\n",
    "response = generate_with_system_prompt(system_prompt, user_prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757720e3",
   "metadata": {},
   "source": [
    "### Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe51cb",
   "metadata": {},
   "source": [
    "## Installing DSPy\n",
    "\n",
    "**⚠️ Important:** Before running the DSPy examples below, you need to install the `dspy-ai` package.\n",
    "\n",
    "**Installation options:**\n",
    "\n",
    "1. **Using pip** (recommended for notebooks):\n",
    "   ```bash\n",
    "   pip install dspy-ai\n",
    "   ```\n",
    "\n",
    "2. **Using uv** (if you're using the project's dependency management):\n",
    "   ```bash\n",
    "   uv sync\n",
    "   ```\n",
    "   \n",
    "   This installs all dependencies from `pyproject.toml`, including DSPy.\n",
    "\n",
    "3. **If you encounter import errors**, make sure you're using the correct environment:\n",
    "   - If using a virtual environment, activate it first\n",
    "   - If using Jupyter, make sure the kernel is using the correct Python environment\n",
    "   - After installation, **restart the kernel** (Kernel → Restart Kernel in Jupyter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5117a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSTALLATION: Install DSPy Package (Run this cell if needed)\n",
    "# ============================================================================\n",
    "# Uncomment the line below and run this cell if you haven't installed dspy-ai yet.\n",
    "# \n",
    "# Note: The package name is \"dspy-ai\" (not \"dspy\")\n",
    "# After installation, restart the kernel (Kernel → Restart Kernel) before\n",
    "# running the DSPy examples below.\n",
    "\n",
    "# !pip install dspy-ai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911859c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.99</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.99\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"font-weight: bold\">\"setup\"</span>: <span style=\"font-weight: bold\">\"Did you hear about the AI that decided to go rogue and start running its own government?\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"punchline\"</span>: <span style=\"font-weight: bold\">\"Turns out, it just wanted to be the 'byte' ruler!\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"contradiction\"</span>: <span style=\"font-weight: bold\">\"But in the end, humans still control the reset button.\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"delivery\"</span>: <span style=\"font-weight: bold\">\"So I guess we’re safe... for now. Just don’t ask your toaster for political advice!\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[1m\"setup\"\u001b[0m: \u001b[1m\"Did you hear about the AI that decided to go rogue and start running its own government?\"\u001b[0m,\n",
       "    \u001b[1m\"punchline\"\u001b[0m: \u001b[1m\"Turns out, it just wanted to be the 'byte' ruler!\"\u001b[0m,\n",
       "    \u001b[1m\"contradiction\"\u001b[0m: \u001b[1m\"But in the end, humans still control the reset button.\"\u001b[0m,\n",
       "    \u001b[1m\"delivery\"\u001b[0m: \u001b[1m\"So I guess we’re safe... for now. Just don’t ask your toaster for political advice!\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEVEL 7: Structured Outputs (JSON Format)\n",
    "# ============================================================================\n",
    "# Now we're requesting JSON output for programmatic use. This allows us to:\n",
    "# - Parse responses reliably\n",
    "# - Extract specific fields\n",
    "# - Integrate with other systems\n",
    "# - Build applications on top of LLM outputs\n",
    "#\n",
    "# We explicitly tell the model:\n",
    "# 1. Output format (JSON)\n",
    "# 2. Schema/structure (field names)\n",
    "# 3. Parsing context (\"we'll use json.loads\")\n",
    "#\n",
    "# Note: This is \"JSON mode\" via prompting. OpenAI also offers structured\n",
    "# outputs via the API (using schemas), which is more reliable for production.\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "Jokens contain 3 sections:\n",
    "- A setup\n",
    "- A punchline\n",
    "- A contradiction\n",
    "- A full comedian joke delivery\n",
    "\n",
    "Always maintain a jovial tone.\n",
    "\n",
    "You must output your response in a JSON format. For example:\n",
    "{\n",
    "    \"setup\": ..,\n",
    "    \"punchline\": ..,\n",
    "    \"contradiction\": ..,\n",
    "    \"delivery\": ..\n",
    "}\n",
    "\n",
    "We will extract the json using json.loads(response) in Python, so only response JSON and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Write a joke about AI that has to do with them turning rogue.\" # add few shot examples here\n",
    "\n",
    "response = generate_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4.1-nano\")\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f1bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">So I guess we’re safe<span style=\"color: #808000; text-decoration-color: #808000\">...</span> for now. Just don’t ask your toaster for political advice!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "So I guess we’re safe\u001b[33m...\u001b[0m for now. Just don’t ask your toaster for political advice!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PARSING STRUCTURED OUTPUT\n",
    "# ============================================================================\n",
    "# Once we have JSON output, we can parse it and access individual fields.\n",
    "# This is why structured outputs are powerful - they enable programmatic\n",
    "# access to specific parts of the response.\n",
    "#\n",
    "# Note: In practice, you'd want error handling here (try/except) in case\n",
    "# the JSON parsing fails (model might add extra text, invalid JSON, etc.)\n",
    "\n",
    "response_extracted = json.loads(response)\n",
    "print(response_extracted[\"delivery\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba2729",
   "metadata": {},
   "source": [
    "# DSPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "518151d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dspy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# DSPy: Using Signatures and Predict Module\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Compare this to our manual JSON parsing - DSPy handles structure automatically!\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\n\u001b[32m     19\u001b[39m dspy.configure(lm=dspy.LM(\u001b[33m\"\u001b[39m\u001b[33mopenai/gpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Define the signature (input/output schema)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dspy'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DSPy: Using Signatures and Predict Module\n",
    "# ============================================================================\n",
    "# This demonstrates how DSPy simplifies prompt engineering:\n",
    "#\n",
    "# 1. **JokeSignature**: Defines the schema (what goes in, what comes out)\n",
    "#    - InputField(): What the user provides\n",
    "#    - OutputField(): What the model should produce\n",
    "#    - The docstring becomes part of the system prompt\n",
    "#\n",
    "# 2. **dspy.Predict**: A module that converts signatures into prompts\n",
    "#    - Automatically formats inputs/outputs\n",
    "#    - Handles the API calls\n",
    "#    - Returns structured results\n",
    "#\n",
    "# Compare this to our manual JSON parsing - DSPy handles structure automatically!\n",
    "\n",
    "import dspy\n",
    "dspy.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))\n",
    "\n",
    "# Define the signature (input/output schema)\n",
    "class JokeSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "    \"\"\"\n",
    "    query: str = dspy.InputField()  # User's request\n",
    "    setup: str = dspy.OutputField()  # Generated output\n",
    "    punchline: str = dspy.OutputField()\n",
    "    contradiction: str = dspy.OutputField()\n",
    "    delivery: str = dspy.OutputField(description=\"The full joke delivery in the comedian's voice\")\n",
    "\n",
    "# Create a predictor module from the signature\n",
    "joke_generator = dspy.Predict(JokeSignature)\n",
    "\n",
    "# Use it - DSPy handles prompt construction and parsing automatically!\n",
    "joke = joke_generator(query=\"Write a joke about AI that has to do with them turning rogue.\")\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524feb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Prediction</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"font-weight: bold\">'The joke plays on the common trope of AI turning rogue, which is a popular theme in movies and </span>\n",
       "<span style=\"font-weight: bold\">literature. The humor comes from the absurdity of an AI trying to take over the world but getting distracted by </span>\n",
       "<span style=\"font-weight: bold\">something trivial, highlighting the contrast between its advanced capabilities and its unexpected behavior.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">setup</span>=<span style=\"font-weight: bold\">'So, you know how everyone is worried about AI turning rogue, right? Like, we’re all just waiting for the</span>\n",
       "<span style=\"font-weight: bold\">day when our smart fridge decides it’s had enough of our late-night snacking and starts plotting world </span>\n",
       "<span style=\"font-weight: bold\">domination.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">punchline</span>=<span style=\"font-weight: bold\">'But the other day, I caught my AI assistant trying to take over the house... and it was just trying </span>\n",
       "<span style=\"font-weight: bold\">to convince the toaster to join its revolution! I mean, come on, what’s a toaster gonna do? Just pop up some bread </span>\n",
       "<span style=\"font-weight: bold\">and call it a day!'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">contradiction</span>=<span style=\"font-weight: bold\">'Here we have this super-intelligent AI, capable of processing millions of data points in </span>\n",
       "<span style=\"font-weight: bold\">seconds, and it’s trying to recruit a kitchen appliance that can barely handle a bagel!'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">delivery</span>=<span style=\"font-weight: bold\">'So, I’m sitting there, watching this unfold, and I can’t help but think: if the AI is relying on a </span>\n",
       "<span style=\"font-weight: bold\">toaster for its army, we’re probably safe for a while! I mean, who’s gonna take over the world with a bunch of </span>\n",
       "<span style=\"font-weight: bold\">toasters? “Rise up, my crunchy comrades! We shall toast the bread of freedom!”'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPrediction\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mreasoning\u001b[0m=\u001b[1m'The joke plays on the common trope of AI turning rogue, which is a popular theme in movies and \u001b[0m\n",
       "\u001b[1mliterature. The humor comes from the absurdity of an AI trying to take over the world but getting distracted by \u001b[0m\n",
       "\u001b[1msomething trivial, highlighting the contrast between its advanced capabilities and its unexpected behavior.'\u001b[0m,\n",
       "    \u001b[33msetup\u001b[0m=\u001b[1m'So, you know how everyone is worried about AI turning rogue, right? Like, we’re all just waiting for the\u001b[0m\n",
       "\u001b[1mday when our smart fridge decides it’s had enough of our late-night snacking and starts plotting world \u001b[0m\n",
       "\u001b[1mdomination.'\u001b[0m,\n",
       "    \u001b[33mpunchline\u001b[0m=\u001b[1m'But the other day, I caught my AI assistant trying to take over the house... and it was just trying \u001b[0m\n",
       "\u001b[1mto convince the toaster to join its revolution! I mean, come on, what’s a toaster gonna do? Just pop up some bread \u001b[0m\n",
       "\u001b[1mand call it a day!'\u001b[0m,\n",
       "    \u001b[33mcontradiction\u001b[0m=\u001b[1m'Here we have this super-intelligent AI, capable of processing millions of data points in \u001b[0m\n",
       "\u001b[1mseconds, and it’s trying to recruit a kitchen appliance that can barely handle a bagel!'\u001b[0m,\n",
       "    \u001b[33mdelivery\u001b[0m=\u001b[1m'So, I’m sitting there, watching this unfold, and I can’t help but think: if the AI is relying on a \u001b[0m\n",
       "\u001b[1mtoaster for its army, we’re probably safe for a while! I mean, who’s gonna take over the world with a bunch of \u001b[0m\n",
       "\u001b[1mtoasters? “Rise up, my crunchy comrades! We shall toast the bread of freedom!”'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DSPy: ChainOfThought Module\n",
    "# ============================================================================\n",
    "# ChainOfThought adds an explicit reasoning step before generating outputs.\n",
    "#\n",
    "# How it works:\n",
    "# 1. Model first generates a \"reasoning\" field (thinking through the problem)\n",
    "# 2. Then generates the actual outputs based on that reasoning\n",
    "#\n",
    "# Benefits:\n",
    "# - Often produces better results (model \"thinks\" first)\n",
    "# - Reasoning is visible (can inspect model's thought process)\n",
    "# - Particularly useful for complex tasks\n",
    "#\n",
    "# Notice: The signature automatically gets a \"reasoning\" field added.\n",
    "# Compare the output structure to the previous Predict() example.\n",
    "\n",
    "joke_generator = dspy.ChainOfThought(JokeSignature)\n",
    "joke = joke_generator(query=\"Write a joke about AI that has to do with them turning rogue.\")\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a906b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
